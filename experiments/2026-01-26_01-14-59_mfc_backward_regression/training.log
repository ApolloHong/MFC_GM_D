Experiment: 2026-01-26_01-14-59_mfc_backward_regression
Started: 2026-01-26T01:14:59.888609
======================================================================

======================================================================
MFC Configuration (Iterative Backward Regression)
======================================================================
  Physics:    T=1.0, N=50, σ=1.0, dim=1
  Target:     N(1.0, 1.0)
  Initial:    dirac at 0.0
----------------------------------------------------------------------
  Model:      hidden=64, layers=3, time_emb=16
  Training:   100 iterations × 100 epochs, batch=2048, lr=0.001
  λ (terminal_weight): 10.0
======================================================================

[01:14:59] Initialized solver on device: cpu
[01:14:59] Number of networks: 50
[01:14:59] Polyak averaging τ: 0.5
[01:14:59] Total parameters (trainable): 428,850
[01:14:59] ======================================================================
[01:14:59] Starting Iterative Backward Regression (Polyak Averaging)
[01:14:59] ======================================================================
[01:14:59] Iterations: 100
[01:14:59] Backward epochs per step: 100
[01:14:59] Batch size: 2048
[01:14:59] Polyak τ: 0.5
[01:14:59] λ (terminal_weight): 10.0
[01:14:59] Target: N(1.0, 1.0)
[01:14:59] ======================================================================
[01:15:07] Iter [  1/100] | Loss: 2.520106 | μ=0.000 (Δ=1.000), σ=0.945 (Δ=0.055)
[01:15:28] Iter [  5/100] | Loss: 1.659051 | μ=0.978 (Δ=0.022), σ=0.181 (Δ=0.819)
[01:15:55] Iter [ 10/100] | Loss: 1.627670 | μ=0.826 (Δ=0.174), σ=0.176 (Δ=0.824)
[01:16:21] Iter [ 15/100] | Loss: 1.638758 | μ=1.008 (Δ=0.008), σ=0.182 (Δ=0.818)
[01:16:48] Iter [ 20/100] | Loss: 1.650500 | μ=0.835 (Δ=0.165), σ=0.181 (Δ=0.819)
[01:17:14] Iter [ 25/100] | Loss: 1.589100 | μ=0.937 (Δ=0.063), σ=0.172 (Δ=0.828)
[01:17:41] Iter [ 30/100] | Loss: 1.641809 | μ=0.868 (Δ=0.132), σ=0.178 (Δ=0.822)
[01:18:07] Iter [ 35/100] | Loss: 1.602772 | μ=0.924 (Δ=0.076), σ=0.180 (Δ=0.820)
[01:18:33] Iter [ 40/100] | Loss: 1.648488 | μ=0.893 (Δ=0.107), σ=0.182 (Δ=0.818)
[01:18:59] Iter [ 45/100] | Loss: 1.570012 | μ=0.906 (Δ=0.094), σ=0.175 (Δ=0.825)
[01:19:25] Iter [ 50/100] | Loss: 1.595644 | μ=0.927 (Δ=0.073), σ=0.176 (Δ=0.824)
[01:19:51] Iter [ 55/100] | Loss: 1.660946 | μ=0.895 (Δ=0.105), σ=0.183 (Δ=0.817)
[01:20:17] Iter [ 60/100] | Loss: 1.635164 | μ=0.951 (Δ=0.049), σ=0.181 (Δ=0.819)
[01:20:43] Iter [ 65/100] | Loss: 1.649214 | μ=0.894 (Δ=0.106), σ=0.179 (Δ=0.821)
[01:21:09] Iter [ 70/100] | Loss: 1.668745 | μ=0.911 (Δ=0.089), σ=0.183 (Δ=0.817)
[01:21:34] Iter [ 75/100] | Loss: 1.689688 | μ=0.897 (Δ=0.103), σ=0.186 (Δ=0.814)
[01:22:01] Iter [ 80/100] | Loss: 1.633053 | μ=0.902 (Δ=0.098), σ=0.181 (Δ=0.819)
[01:22:27] Iter [ 85/100] | Loss: 1.635989 | μ=0.913 (Δ=0.087), σ=0.178 (Δ=0.822)
[01:22:52] Iter [ 90/100] | Loss: 1.665212 | μ=0.904 (Δ=0.096), σ=0.184 (Δ=0.816)
[01:23:18] Iter [ 95/100] | Loss: 1.658725 | μ=0.910 (Δ=0.090), σ=0.182 (Δ=0.818)
[01:23:43] Iter [100/100] | Loss: 1.654748 | μ=0.938 (Δ=0.062), σ=0.183 (Δ=0.817)
[01:23:43] ======================================================================
[01:23:43] Training Complete! Evaluating with target networks...
[01:23:43] Final Mean: 0.9443 (target: 1.0)
[01:23:43] Final Std:  0.1824 (target: 1.0)
[01:23:43] ======================================================================
[01:23:44] Saved plot: trajectories.png
[01:23:44] Saved plot: terminal_distribution.png
[01:23:44] Saved plot: statistics_evolution.png
[01:23:44] Saved all visualization plots

======================================================================
FINAL RESULTS
======================================================================
  history: {'iteration_losses': [np.float64(2.52010568022728), np.float64(1.926918637175113), np.float64(1.7564983971090988), np.float64(1.6378283780254423), np.float64(1.65905064240098), np.float64(1.6269052591174842), np.float64(1.664671454280615), np.float64(1.6058439270034433), np.float64(1.6346037827432156), np.float64(1.6276702257245779), np.float64(1.648850656375289), np.float64(1.627418483272195), np.float64(1.6475434854999185), np.float64(1.6458259961381554), np.float64(1.6387576153501868), np.float64(1.6734098939970137), np.float64(1.6155164302513003), np.float64(1.6292559279501437), np.float64(1.6294117143377662), np.float64(1.6504999880865217), np.float64(1.697251233831048), np.float64(1.6369981525279582), np.float64(1.630537341721356), np.float64(1.626922636218369), np.float64(1.5891003566235304), np.float64(1.6383915613219142), np.float64(1.6493135300651192), np.float64(1.6799478102102876), np.float64(1.6504185098037123), np.float64(1.6418090866506099), np.float64(1.646343488767743), np.float64(1.6377657925710083), np.float64(1.6526654614135623), np.float64(1.656280881650746), np.float64(1.6027715792506934), np.float64(1.660758334994316), np.float64(1.644932899698615), np.float64(1.6291887548007071), np.float64(1.6558970963209867), np.float64(1.6484884730353953), np.float64(1.6710070475563408), np.float64(1.6916311469301581), np.float64(1.6362249560654163), np.float64(1.646316631026566), np.float64(1.5700120799988508), np.float64(1.6221760523691773), np.float64(1.6553579678758978), np.float64(1.5954123171418906), np.float64(1.710034478828311), np.float64(1.5956436846032738), np.float64(1.6534793294221162), np.float64(1.6310080380365253), np.float64(1.6877721886709331), np.float64(1.6225185828283428), np.float64(1.6609455351531506), np.float64(1.6371678056195378), np.float64(1.611782995276153), np.float64(1.6479350784793496), np.float64(1.6954170700907707), np.float64(1.6351641077920795), np.float64(1.6568996242061258), np.float64(1.603308619633317), np.float64(1.677433143146336), np.float64(1.6286691289395094), np.float64(1.6492144580185413), np.float64(1.591486388221383), np.float64(1.6534076401218771), np.float64(1.6661997937224806), np.float64(1.6312124531716108), np.float64(1.6687449073791505), np.float64(1.6050735472142696), np.float64(1.6508775189891458), np.float64(1.604962381273508), np.float64(1.6013726611062884), np.float64(1.6896875166893006), np.float64(1.6026717024296522), np.float64(1.6460460267961026), np.float64(1.6314632301405072), np.float64(1.6203780889511108), np.float64(1.6330529301986099), np.float64(1.616605659276247), np.float64(1.6588385770842433), np.float64(1.6235341088846327), np.float64(1.6233815402537584), np.float64(1.6359891455248), np.float64(1.6509891917929054), np.float64(1.6708768863230943), np.float64(1.5936453066393732), np.float64(1.6151935364678502), np.float64(1.6652118457853795), np.float64(1.621081935558468), np.float64(1.645732654221356), np.float64(1.6397561065107584), np.float64(1.602598180025816), np.float64(1.6587253791093826), np.float64(1.6118780249729752), np.float64(1.6392685690522193), np.float64(1.627865151129663), np.float64(1.639861535038799), np.float64(1.654748273193836)], 'terminal_means': [np.float32(0.00022334093), np.float32(0.7135626), np.float32(0.7915278), np.float32(0.88222784), np.float32(0.97805595), np.float32(1.0225729), np.float32(1.0275207), np.float32(0.9624487), np.float32(0.8918996), np.float32(0.82596105), np.float32(0.8141149), np.float32(0.84492534), np.float32(0.8740631), np.float32(0.9655961), np.float32(1.0079017), np.float32(1.0077051), np.float32(0.94707495), np.float32(0.8822411), np.float32(0.8442886), np.float32(0.83461046), np.float32(0.8551389), np.float32(0.8951278), np.float32(0.9332158), np.float32(0.93672776), np.float32(0.9367137), np.float32(0.92508775), np.float32(0.91054), np.float32(0.8837334), np.float32(0.866235), np.float32(0.86783504), np.float32(0.8966352), np.float32(0.90780324), np.float32(0.93303), np.float32(0.9383997), np.float32(0.92407537), np.float32(0.914752), np.float32(0.90762293), np.float32(0.8868515), np.float32(0.879538), np.float32(0.8932889), np.float32(0.9162179), np.float32(0.93258643), np.float32(0.93255633), np.float32(0.902805), np.float32(0.90557605), np.float32(0.8977453), np.float32(0.89882815), np.float32(0.90329516), np.float32(0.9148791), np.float32(0.92726576), np.float32(0.92918324), np.float32(0.9341599), np.float32(0.9199046), np.float32(0.9113357), np.float32(0.89479524), np.float32(0.90266), np.float32(0.91486067), np.float32(0.9226452), np.float32(0.94129074), np.float32(0.95084006), np.float32(0.9293004), np.float32(0.9069003), np.float32(0.894143), np.float32(0.8869982), np.float32(0.8935226), np.float32(0.92675847), np.float32(0.9493727), np.float32(0.94530696), np.float32(0.92842853), np.float32(0.9111786), np.float32(0.9048007), np.float32(0.9018739), np.float32(0.8875261), np.float32(0.9013998), np.float32(0.8965061), np.float32(0.91449165), np.float32(0.9211128), np.float32(0.90538526), np.float32(0.90966785), np.float32(0.90240467), np.float32(0.9017725), np.float32(0.9141), np.float32(0.9058701), np.float32(0.8980411), np.float32(0.9128487), np.float32(0.9167892), np.float32(0.92562735), np.float32(0.91536546), np.float32(0.9243836), np.float32(0.9041208), np.float32(0.8980211), np.float32(0.91361), np.float32(0.9129429), np.float32(0.917634), np.float32(0.9096167), np.float32(0.89749825), np.float32(0.8925936), np.float32(0.90163004), np.float32(0.91420114), np.float32(0.9380212)], 'terminal_vars': [np.float32(0.89287734), np.float32(0.1036447), np.float32(0.040400483), np.float32(0.03164962), np.float32(0.032919772), np.float32(0.03212434), np.float32(0.033587415), np.float32(0.032074615), np.float32(0.031729244), np.float32(0.0308034), np.float32(0.033271916), np.float32(0.03241298), np.float32(0.035012104), np.float32(0.031853333), np.float32(0.033072107), np.float32(0.033846874), np.float32(0.03103804), np.float32(0.031574555), np.float32(0.030711597), np.float32(0.032643735), np.float32(0.036031064), np.float32(0.032083727), np.float32(0.031938992), np.float32(0.03216161), np.float32(0.029459087), np.float32(0.032827426), np.float32(0.03243295), np.float32(0.034049787), np.float32(0.033538498), np.float32(0.031778146), np.float32(0.032261055), np.float32(0.032590337), np.float32(0.034574483), np.float32(0.032409307), np.float32(0.032435726), np.float32(0.032803178), np.float32(0.033286124), np.float32(0.03198296), np.float32(0.034259953), np.float32(0.032997362), np.float32(0.03275935), np.float32(0.0336017), np.float32(0.03244549), np.float32(0.03298139), np.float32(0.030729583), np.float32(0.03128688), np.float32(0.033225726), np.float32(0.030099187), np.float32(0.0354757), np.float32(0.03108592), np.float32(0.032983072), np.float32(0.031416867), np.float32(0.03493366), np.float32(0.032817446), np.float32(0.033434127), np.float32(0.03274816), np.float32(0.030844048), np.float32(0.032706276), np.float32(0.035407208), np.float32(0.032896187), np.float32(0.032387834), np.float32(0.031807058), np.float32(0.033520218), np.float32(0.031902544), np.float32(0.032089524), np.float32(0.031220375), np.float32(0.033442877), np.float32(0.033055812), np.float32(0.033368833), np.float32(0.03344088), np.float32(0.03164777), np.float32(0.0321526), np.float32(0.031533215), np.float32(0.03131984), np.float32(0.03463438), np.float32(0.031123098), np.float32(0.032530695), np.float32(0.032153092), np.float32(0.032256253), np.float32(0.032767195), np.float32(0.030878792), np.float32(0.035986617), np.float32(0.032133833), np.float32(0.031697333), np.float32(0.03169588), np.float32(0.03362046), np.float32(0.032967694), np.float32(0.031490844), np.float32(0.03229256), np.float32(0.033763368), np.float32(0.031327), np.float32(0.03311072), np.float32(0.03266667), np.float32(0.03154307), np.float32(0.03302157), np.float32(0.030712612), np.float32(0.0345043), np.float32(0.031472515), np.float32(0.032703906), np.float32(0.033426072)]}
  final_mean: 0.9442974328994751
  final_var: 0.03325198218226433
  final_trajectories: tensor([[[ 0.0000],
         [ 0.0000],
         [ 0.0000],
         ...,
         [ 0.0000],
         [ 0.0000],
         [ 0.0000]],

        [[ 0.0404],
         [ 0.1067],
         [ 0.2245],
         ...,
         [-0.1281],
         [ 0.2065],
         [ 0.0147]],

        [[ 0.2750],
         [ 0.0288],
         [ 0.2491],
         ...,
         [ 0.1727],
         [ 0.1398],
         [ 0.0391]],

        ...,

        [[ 0.8211],
         [ 0.7484],
         [ 0.4261],
         ...,
         [ 0.9324],
         [ 1.3849],
         [ 0.9986]],

        [[ 0.8228],
         [ 0.7799],
         [ 0.7732],
         ...,
         [ 1.1252],
         [ 1.1372],
         [ 1.1693]],

        [[ 0.8852],
         [ 1.0338],
         [ 0.7105],
         ...,
         [ 1.0739],
         [ 1.1571],
         [ 0.9711]]])

Completed: 2026-01-26T01:23:50.789290
